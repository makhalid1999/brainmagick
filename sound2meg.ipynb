{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makhalid1999/brainmagick/blob/main/sound2meg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B-VS6pah7f6",
        "outputId": "4a35024f-fa21-4eab-9a0a-3a3896271cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'brainmagick'...\n",
            "remote: Enumerating objects: 214, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 214 (delta 61), reused 31 (delta 31), pack-reused 83\u001b[K\n",
            "Receiving objects: 100% (214/214), 829.71 KiB | 17.65 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/makhalid1999/brainmagick.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZEmxjEqIiRPR",
        "outputId": "d0be7f8d-ad8f-4fe4-d86b-d1aed2671ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 7)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 8)) (2.1.0+cu118)\n",
            "Collecting hydra-core>=1.1 (from -r /content/brainmagick/requirements.txt (line 9))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting julius (from -r /content/brainmagick/requirements.txt (line 10))\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mne>=0.24.1 (from -r /content/brainmagick/requirements.txt (line 11))\n",
            "  Downloading mne-1.6.0-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 12)) (1.5.3)\n",
            "Collecting python-Levenshtein (from -r /content/brainmagick/requirements.txt (line 13))\n",
            "  Downloading python_Levenshtein-0.23.0-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 14)) (1.2.2)\n",
            "Collecting wordfreq (from -r /content/brainmagick/requirements.txt (line 15))\n",
            "  Downloading wordfreq-3.1.1-py3-none-any.whl (56.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 16)) (7.4.3)\n",
            "Collecting pytest-cov>=2.6.1 (from -r /content/brainmagick/requirements.txt (line 17))\n",
            "  Downloading pytest_cov-4.1.0-py3-none-any.whl (21 kB)\n",
            "Collecting flake8 (from -r /content/brainmagick/requirements.txt (line 18))\n",
            "  Downloading flake8-6.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy (from -r /content/brainmagick/requirements.txt (line 19))\n",
            "  Downloading mypy-1.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 20)) (1.23.5)\n",
            "Collecting types-PyYAML (from -r /content/brainmagick/requirements.txt (line 21))\n",
            "  Downloading types_PyYAML-6.0.12.12-py3-none-any.whl (14 kB)\n",
            "Collecting spacy<2.4.0 (from -r /content/brainmagick/requirements.txt (line 22))\n",
            "  Downloading spacy-2.3.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r /content/brainmagick/requirements.txt (line 23))\n",
            "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 24)) (0.58.1)\n",
            "Collecting mne_bids (from -r /content/brainmagick/requirements.txt (line 25))\n",
            "  Downloading mne_bids-0.14-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting osfclient (from -r /content/brainmagick/requirements.txt (line 26))\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: matplotlib>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 27)) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 28)) (1.11.4)\n",
            "Collecting submitit (from -r /content/brainmagick/requirements.txt (line 29))\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dora-search (from -r /content/brainmagick/requirements.txt (line 30))\n",
            "  Downloading dora_search-0.1.12.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flashy (from -r /content/brainmagick/requirements.txt (line 31))\n",
            "  Downloading flashy-0.0.2.tar.gz (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.15.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 32)) (4.35.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r /content/brainmagick/requirements.txt (line 33)) (6.0.1)\n",
            "Collecting autoreject (from -r /content/brainmagick/requirements.txt (line 34))\n",
            "  Downloading autoreject-0.4.3-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (2.1.0)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.1->-r /content/brainmagick/requirements.txt (line 9))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->-r /content/brainmagick/requirements.txt (line 9))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->-r /content/brainmagick/requirements.txt (line 9)) (23.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11)) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11)) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11)) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->-r /content/brainmagick/requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->-r /content/brainmagick/requirements.txt (line 12)) (2023.3.post1)\n",
            "Collecting Levenshtein==0.23.0 (from python-Levenshtein->-r /content/brainmagick/requirements.txt (line 13))\n",
            "  Downloading Levenshtein-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.1.0 (from Levenshtein==0.23.0->python-Levenshtein->-r /content/brainmagick/requirements.txt (line 13))\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/brainmagick/requirements.txt (line 14)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/brainmagick/requirements.txt (line 14)) (3.2.0)\n",
            "Collecting ftfy>=6.1 (from wordfreq->-r /content/brainmagick/requirements.txt (line 15))\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq->-r /content/brainmagick/requirements.txt (line 15)) (3.3.0)\n",
            "Collecting locate<2.0.0,>=1.1.1 (from wordfreq->-r /content/brainmagick/requirements.txt (line 15))\n",
            "  Downloading locate-1.1.1-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from wordfreq->-r /content/brainmagick/requirements.txt (line 15)) (1.0.7)\n",
            "Collecting regex>=2023.10.3 (from wordfreq->-r /content/brainmagick/requirements.txt (line 15))\n",
            "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/brainmagick/requirements.txt (line 16)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/brainmagick/requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/brainmagick/requirements.txt (line 16)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/brainmagick/requirements.txt (line 16)) (2.0.1)\n",
            "Collecting coverage[toml]>=5.2.1 (from pytest-cov>=2.6.1->-r /content/brainmagick/requirements.txt (line 17))\n",
            "  Downloading coverage-7.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.8.0,>=0.7.0 (from flake8->-r /content/brainmagick/requirements.txt (line 18))\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->-r /content/brainmagick/requirements.txt (line 18))\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.2.0,>=3.1.0 (from flake8->-r /content/brainmagick/requirements.txt (line 18))\n",
            "  Downloading pyflakes-3.1.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=1.0.0 (from mypy->-r /content/brainmagick/requirements.txt (line 19))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (3.0.9)\n",
            "Collecting thinc<7.5.0,>=7.4.1 (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22))\n",
            "  Downloading thinc-7.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.4.0 (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22))\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<1.1.0,>=1.0.2 (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22))\n",
            "  Downloading srsly-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (369 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.2/369.2 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7 (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22))\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (67.7.2)\n",
            "Collecting plac<1.2.0,>=0.9.6 (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22))\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (2.31.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/brainmagick/requirements.txt (line 23)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r /content/brainmagick/requirements.txt (line 23))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/brainmagick/requirements.txt (line 23)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r /content/brainmagick/requirements.txt (line 23))\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r /content/brainmagick/requirements.txt (line 23))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->-r /content/brainmagick/requirements.txt (line 23))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/brainmagick/requirements.txt (line 23)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/brainmagick/requirements.txt (line 23)) (3.20.3)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r /content/brainmagick/requirements.txt (line 24)) (0.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from osfclient->-r /content/brainmagick/requirements.txt (line 26)) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->-r /content/brainmagick/requirements.txt (line 27)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->-r /content/brainmagick/requirements.txt (line 27)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->-r /content/brainmagick/requirements.txt (line 27)) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->-r /content/brainmagick/requirements.txt (line 27)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->-r /content/brainmagick/requirements.txt (line 27)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->-r /content/brainmagick/requirements.txt (line 27)) (3.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->-r /content/brainmagick/requirements.txt (line 29)) (2.2.1)\n",
            "Collecting retrying (from dora-search->-r /content/brainmagick/requirements.txt (line 30))\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting treetable (from dora-search->-r /content/brainmagick/requirements.txt (line 30))\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorlog (from flashy->-r /content/brainmagick/requirements.txt (line 31))\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.15.0->-r /content/brainmagick/requirements.txt (line 32)) (0.19.4)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.15.0->-r /content/brainmagick/requirements.txt (line 32)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.15.0->-r /content/brainmagick/requirements.txt (line 32)) (0.4.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1->wordfreq->-r /content/brainmagick/requirements.txt (line 15)) (0.2.12)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r /content/brainmagick/requirements.txt (line 23))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5io (from mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11))\n",
            "  Downloading h5io-0.1.9-py3-none-any.whl (13 kB)\n",
            "Collecting pymatreader (from mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11))\n",
            "  Downloading pymatreader-0.0.32-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11)) (4.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->-r /content/brainmagick/requirements.txt (line 22)) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5->-r /content/brainmagick/requirements.txt (line 7)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r /content/brainmagick/requirements.txt (line 23))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from h5io->mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11)) (3.9.0)\n",
            "Collecting xmltodict (from pymatreader->mne>=0.24.1->-r /content/brainmagick/requirements.txt (line 11))\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, julius, dora-search, flashy, treetable\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=7f9bc3083ad1c43a5b9523f59ff123ff498fe40d51d20f3d990d6a240dfef249\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=f426743878c71894a69566532919935c7d3375119defe5457df09c263f68bccf\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75090 sha256=55f8feff9c6b3baddfec38f537d70c2a09295605047d65740e988542f6d8d488\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c2/c0/bea5cc405497284d584b958f293ef32c23bad42ae5e44d973c\n",
            "  Building wheel for flashy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashy: filename=flashy-0.0.2-py3-none-any.whl size=34524 sha256=25764db75e67f157f28b386d6ce40af4a89e8af38558c5ae516d5ae1cc785e1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/bd/3d/16c6bc059203299f37b6014643b739afb7f6d1be13a94fc2f7\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7333 sha256=d5eda53938c5383f99ebe2075153ce5bd39d88bf7576645f375abc4d70877611\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/55/0e/91c3655bdb162446f8a7cd477579397544454a63ae7c599c0c\n",
            "Successfully built antlr4-python3-runtime julius dora-search flashy treetable\n",
            "Installing collected packages: wasabi, types-PyYAML, plac, antlr4-python3-runtime, xmltodict, treetable, submitit, srsly, smmap, setproctitle, sentry-sdk, retrying, regex, rapidfuzz, pyflakes, pycodestyle, omegaconf, mypy-extensions, mccabe, locate, ftfy, docker-pycreds, coverage, colorlog, catalogue, wordfreq, thinc, pymatreader, osfclient, mypy, Levenshtein, hydra-core, h5io, gitdb, flake8, spacy, python-Levenshtein, pytest-cov, mne, julius, GitPython, dora-search, wandb, mne_bids, flashy, autoreject\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.8\n",
            "    Uninstalling srsly-2.4.8:\n",
            "      Successfully uninstalled srsly-2.4.8\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.6.3\n",
            "    Uninstalling regex-2023.6.3:\n",
            "      Successfully uninstalled regex-2023.6.3\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.10\n",
            "    Uninstalling catalogue-2.0.10:\n",
            "      Successfully uninstalled catalogue-2.0.10\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.12\n",
            "    Uninstalling thinc-8.1.12:\n",
            "      Successfully uninstalled thinc-8.1.12\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "confection 0.1.4 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.7 which is incompatible.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 2.3.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.40 Levenshtein-0.23.0 antlr4-python3-runtime-4.9.3 autoreject-0.4.3 catalogue-1.0.2 colorlog-6.8.0 coverage-7.3.2 docker-pycreds-0.4.0 dora-search-0.1.12 flake8-6.1.0 flashy-0.0.2 ftfy-6.1.3 gitdb-4.0.11 h5io-0.1.9 hydra-core-1.3.2 julius-0.2.7 locate-1.1.1 mccabe-0.7.0 mne-1.6.0 mne_bids-0.14 mypy-1.7.1 mypy-extensions-1.0.0 omegaconf-2.3.0 osfclient-0.0.5 plac-1.1.3 pycodestyle-2.11.1 pyflakes-3.1.0 pymatreader-0.0.32 pytest-cov-4.1.0 python-Levenshtein-0.23.0 rapidfuzz-3.5.2 regex-2023.10.3 retrying-1.3.4 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 spacy-2.3.9 srsly-1.0.7 submitit-1.5.1 thinc-7.4.6 treetable-0.2.5 types-PyYAML-6.0.12.12 wandb-0.16.1 wasabi-0.10.1 wordfreq-3.1.1 xmltodict-0.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r /content/brainmagick/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd brainmagick && HYDRA_FULL_ERROR=1 dora grid mygrid '!seed' '!features' '!wer_random' --dry_run --init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwN-yBxc6yBt",
        "outputId": "941ec7a6-d64a-476f-eb91-5361317d7a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hostname 6ba44a4dd73e not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "2023-11-28 14:22:20.450899: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 14:22:20.450957: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 14:22:20.450989: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 14:22:20.458845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-28 14:22:21.453757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Monitoring Grid mygrid\n",
            "Base name:  dse.n_recordings=15 dse.selections=['brennan2019']\n",
            "\u001b[1m\u001b[0m          Meta           |   train    |     valid      |     test    \u001b[0m\u001b[0m\n",
            "\u001b[1m\u001b[38;5;245mi  n  sta       sig  sid | ep    loss |   loss    best |   wer  wer_v\u001b[0m\u001b[0m\n",
            "\u001b[0m0     N/A  f2870bd1      | 13  4.2313 | 6.4159  5.5680 | 0.986  0.707\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd brainmagick && HYDRA_FULL_ERROR=1 dora run -f f2870bd1 -d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8FLelQyWnfE",
        "outputId": "fbc6e215-83e1-44ab-c454-16b3f0ee06de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hostname 6ba44a4dd73e not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "2023-11-28 13:09:48.716203: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 13:09:48.716261: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 13:09:48.716285: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 13:09:48.724402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-28 13:09:49.752228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1mParser\u001b[0m Injecting argv ['norm.max_scale=20', 'dset.n_recordings=15', 'dset.selections=[\"brennan2019\"]'] from sig f2870bd1\n",
            "\u001b[1mExecutor:\u001b[0m Starting 1 worker processes for DDP.\n",
            "Hostname 6ba44a4dd73e not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "2023-11-28 13:09:57.068719: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 13:09:57.068787: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 13:09:57.068814: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 13:09:58.144102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
            "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
            "  ret = run_job(\n",
            "[2023-11-28 13:10:01,592][bm._env][WARNING] - Hostname 6ba44a4dd73e not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "[2023-11-28 13:10:01,593][bm.train][INFO] - For logs, checkpoints and samples, check /content/brainmagick/outputs/xps/f2870bd1.\n",
            "[2023-11-28 13:10:01,593][bm.train][INFO] - Caching intermediate data under /content/brainmagick/cache.\n",
            "[\u001b[36m11-28 13:10:01\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
            "[\u001b[36m11-28 13:10:14\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 3/15 | 7.11 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:10:14\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 6/15 | 8.34 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:10:15\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 9/15 | 8.90 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:10:15\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 12/15 | 9.16 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:10:15\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - # Examples (train | valid | test): 11934 | 2800 | 2846\u001b[0m\n",
            "[\u001b[36m11-28 13:10:18\u001b[0m][\u001b[34mbm.train\u001b[0m][\u001b[32mINFO\u001b[0m] - Model hash: e1c1845dd7505b632ae3cc169ac842f06cef5aad\u001b[0m\n",
            "[\u001b[36m11-28 13:10:19\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scaler. Dataset size=11934 samples.\u001b[0m\n",
            "[\u001b[36m11-28 13:11:05\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scalers | 3/15 | 11.7 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:11:30\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scalers | 6/15 | 10.3 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:12:15\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scalers | 9/15 | 11.6 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:12:41\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scalers | 12/15 | 10.9 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:13:28\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - features collected for norm: torch.Size([1386240, 1024])\u001b[0m\n",
            "[\u001b[36m11-28 13:14:19\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scaler cache file /content/brainmagick/cache/scaler/fc6ef1be894fc200/bf21a9e8fbc5a384.pkl\u001b[0m\n",
            "[\u001b[36m11-28 13:15:24\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 9/47 | 0.15 it/sec | loss 5.6547\u001b[0m\n",
            "[\u001b[36m11-28 13:16:01\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 18/47 | 0.19 it/sec | loss 5.6269\u001b[0m\n",
            "[\u001b[36m11-28 13:16:42\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 27/47 | 0.20 it/sec | loss 5.6101\u001b[0m\n",
            "[\u001b[36m11-28 13:17:19\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 36/47 | 0.21 it/sec | loss 5.6000\u001b[0m\n",
            "[\u001b[36m11-28 13:17:50\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 45/47 | 0.22 it/sec | loss 5.5912\u001b[0m\n",
            "[\u001b[36m11-28 13:17:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 1 | loss=5.5799 | duration=213.0358\u001b[0m\n",
            "[\u001b[36m11-28 13:18:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 2/11 | 20.0 sec/it | loss 5.5792\u001b[0m\n",
            "[\u001b[36m11-28 13:18:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 4/11 | 13.3 sec/it | loss 5.5810\u001b[0m\n",
            "[\u001b[36m11-28 13:19:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 6/11 | 10.6 sec/it | loss 5.5842\u001b[0m\n",
            "[\u001b[36m11-28 13:20:02\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 8/11 | 14.5 sec/it | loss 5.5778\u001b[0m\n",
            "[\u001b[36m11-28 13:20:07\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 10/11 | 12.2 sec/it | loss 5.5757\u001b[0m\n",
            "[\u001b[36m11-28 13:20:07\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 5.5757\u001b[0m\n",
            "[\u001b[36m11-28 13:20:07\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 1 | loss=5.5757 | duration=135.1559\u001b[0m\n",
            "[\u001b[36m11-28 13:21:24\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 2/12 | 25.5 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:21:30\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 4/12 | 16.5 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:21:36\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 6/12 | 12.7 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:21:42\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 8/12 | 10.5 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:21:48\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 10/12 | 0.11 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:21:56\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - wer 2846 negatives selected\u001b[0m\n",
            "[\u001b[36m11-28 13:22:04\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 569/2846 | 90.94 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:22:10\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 1138/2846 | 90.83 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:22:16\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 1707/2846 | 90.90 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:22:23\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 2276/2846 | 90.92 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:22:29\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 2845/2846 | 90.84 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:22:30\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTest Summary | Epoch 1 | wer=97.927% | wer_vocab=71.082% | duration=142.4463\u001b[0m\n",
            "[\u001b[36m11-28 13:22:30\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 13:23:39\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 9/47 | 0.14 it/sec | loss 5.5412\u001b[0m\n",
            "[\u001b[36m11-28 13:24:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 18/47 | 0.18 it/sec | loss 5.5407\u001b[0m\n",
            "[\u001b[36m11-28 13:24:58\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 27/47 | 0.19 it/sec | loss 5.5422\u001b[0m\n",
            "[\u001b[36m11-28 13:25:39\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 36/47 | 0.20 it/sec | loss 5.5438\u001b[0m\n",
            "[\u001b[36m11-28 13:26:10\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 45/47 | 0.21 it/sec | loss 5.5432\u001b[0m\n",
            "[\u001b[36m11-28 13:26:12\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 2 | loss=5.5322 | duration=222.2671\u001b[0m\n",
            "[\u001b[36m11-28 13:26:45\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 2/11 | 10.9 sec/it | loss 5.5855\u001b[0m\n",
            "[\u001b[36m11-28 13:26:50\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 4/11 | 0.13 it/sec | loss 5.5883\u001b[0m\n",
            "[\u001b[36m11-28 13:27:00\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 6/11 | 0.15 it/sec | loss 5.5827\u001b[0m\n",
            "[\u001b[36m11-28 13:27:05\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 8/11 | 0.17 it/sec | loss 5.5797\u001b[0m\n",
            "[\u001b[36m11-28 13:27:13\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 10/11 | 0.18 it/sec | loss 5.5701\u001b[0m\n",
            "[\u001b[36m11-28 13:27:13\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 5.5701\u001b[0m\n",
            "[\u001b[36m11-28 13:27:13\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 2 | loss=5.5701 | duration=60.5847\u001b[0m\n",
            "[\u001b[36m11-28 13:27:53\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 2/12 | 13.2 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:27:59\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 4/12 | 0.11 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:05\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 6/12 | 0.13 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:11\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 8/12 | 0.15 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:18\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 10/12 | 0.17 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:26\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - wer 2846 negatives selected\u001b[0m\n",
            "[\u001b[36m11-28 13:28:33\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 569/2846 | 90.77 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:40\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 1138/2846 | 90.89 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:46\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 1707/2846 | 90.80 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:52\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 2276/2846 | 90.80 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:58\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 2845/2846 | 90.85 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:28:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTest Summary | Epoch 2 | wer=97.786% | wer_vocab=69.466% | duration=106.3363\u001b[0m\n",
            "[\u001b[36m11-28 13:28:59\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 13:30:09\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 9/47 | 0.14 it/sec | loss 5.5151\u001b[0m\n",
            "[\u001b[36m11-28 13:30:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 18/47 | 0.17 it/sec | loss 5.5229\u001b[0m\n",
            "[\u001b[36m11-28 13:31:25\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 27/47 | 0.19 it/sec | loss 5.5261\u001b[0m\n",
            "[\u001b[36m11-28 13:32:09\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 36/47 | 0.20 it/sec | loss 5.5259\u001b[0m\n",
            "[\u001b[36m11-28 13:32:41\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 45/47 | 0.21 it/sec | loss 5.5230\u001b[0m\n",
            "[\u001b[36m11-28 13:32:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 3 | loss=5.5125 | duration=223.3737\u001b[0m\n",
            "[\u001b[36m11-28 13:33:19\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 2/11 | 11.9 sec/it | loss 5.5659\u001b[0m\n",
            "[\u001b[36m11-28 13:33:23\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 4/11 | 0.12 it/sec | loss 5.5614\u001b[0m\n",
            "[\u001b[36m11-28 13:33:33\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/11 | 0.14 it/sec | loss 5.5606\u001b[0m\n",
            "[\u001b[36m11-28 13:33:37\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 8/11 | 0.17 it/sec | loss 5.5804\u001b[0m\n",
            "[\u001b[36m11-28 13:33:45\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 10/11 | 0.18 it/sec | loss 5.5680\u001b[0m\n",
            "[\u001b[36m11-28 13:33:46\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 5.5680\u001b[0m\n",
            "[\u001b[36m11-28 13:33:46\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 3 | loss=5.5680 | duration=62.8688\u001b[0m\n",
            "[\u001b[36m11-28 13:34:19\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 2/12 | 11.1 sec/it\u001b[0m\n",
            "[\u001b[36m11-28 13:34:26\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 4/12 | 0.13 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:34:34\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 6/12 | 0.15 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:34:43\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 8/12 | 0.16 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:34:49\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 10/12 | 0.18 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:34:57\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - wer 2846 negatives selected\u001b[0m\n",
            "[\u001b[36m11-28 13:35:04\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 569/2846 | 91.28 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:35:10\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 1138/2846 | 91.25 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:35:16\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 1707/2846 | 91.16 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:35:23\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 2276/2846 | 91.11 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:35:29\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 2845/2846 | 91.09 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 13:35:29\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTest Summary | Epoch 3 | wer=98.595% | wer_vocab=70.696% | duration=103.7245\u001b[0m\n",
            "[\u001b[36m11-28 13:35:29\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 13:36:34\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 9/47 | 0.16 it/sec | loss 5.5097\u001b[0m\n",
            "[\u001b[36m11-28 13:37:17\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 18/47 | 0.18 it/sec | loss 5.5047\u001b[0m\n",
            "[\u001b[36m11-28 13:37:54\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 27/47 | 0.20 it/sec | loss 5.5047\u001b[0m\n",
            "[\u001b[36m11-28 13:38:37\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 36/47 | 0.20 it/sec | loss 5.5019\u001b[0m\n",
            "[\u001b[36m11-28 13:39:10\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 45/47 | 0.21 it/sec | loss 5.4990\u001b[0m\n",
            "[\u001b[36m11-28 13:39:12\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 4 | loss=5.4878 | duration=222.6022\u001b[0m\n",
            "[\u001b[36m11-28 13:39:49\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 2/11 | 12.1 sec/it | loss 5.6030\u001b[0m\n",
            "[\u001b[36m11-28 13:39:54\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 4/11 | 0.12 it/sec | loss 5.5902\u001b[0m\n",
            "[\u001b[36m11-28 13:40:03\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/11 | 0.14 it/sec | loss 5.6181\u001b[0m\n",
            "[\u001b[36m11-28 13:40:08\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 8/11 | 0.16 it/sec | loss 5.6091\u001b[0m\n",
            "[\u001b[36m11-28 13:40:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 10/11 | 0.17 it/sec | loss 5.6023\u001b[0m\n",
            "[\u001b[36m11-28 13:40:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 4 | loss=5.6023 | duration=63.4023\u001b[0m\n",
            "[\u001b[36m11-28 13:40:16\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 13:41:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 9/47 | 0.17 it/sec | loss 5.4539\u001b[0m\n",
            "[\u001b[36m11-28 13:42:01\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 18/47 | 0.18 it/sec | loss 5.4644\u001b[0m\n",
            "[\u001b[36m11-28 13:42:41\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 27/47 | 0.19 it/sec | loss 5.4723\u001b[0m\n",
            "[\u001b[36m11-28 13:43:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 36/47 | 0.20 it/sec | loss 5.4700\u001b[0m\n",
            "[\u001b[36m11-28 13:43:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 45/47 | 0.21 it/sec | loss 5.4683\u001b[0m\n",
            "[\u001b[36m11-28 13:43:54\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 5 | loss=5.4577 | duration=217.4215\u001b[0m\n",
            "[\u001b[36m11-28 13:44:31\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 2/11 | 12.3 sec/it | loss 5.5882\u001b[0m\n",
            "[\u001b[36m11-28 13:44:37\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 4/11 | 0.12 it/sec | loss 5.5845\u001b[0m\n",
            "[\u001b[36m11-28 13:44:42\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/11 | 0.15 it/sec | loss 5.6032\u001b[0m\n",
            "[\u001b[36m11-28 13:44:46\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 8/11 | 0.17 it/sec | loss 5.5995\u001b[0m\n",
            "[\u001b[36m11-28 13:44:53\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 10/11 | 0.19 it/sec | loss 5.5888\u001b[0m\n",
            "[\u001b[36m11-28 13:44:53\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 5 | loss=5.5888 | duration=59.4782\u001b[0m\n",
            "[\u001b[36m11-28 13:44:53\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 13:45:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 9/47 | 0.15 it/sec | loss 5.4285\u001b[0m\n",
            "[\u001b[36m11-28 13:46:40\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 18/47 | 0.18 it/sec | loss 5.4133\u001b[0m\n",
            "[\u001b[36m11-28 13:47:23\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 27/47 | 0.19 it/sec | loss 5.4169\u001b[0m\n",
            "[\u001b[36m11-28 13:48:03\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 36/47 | 0.20 it/sec | loss 5.4172\u001b[0m\n",
            "[\u001b[36m11-28 13:48:30\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 45/47 | 0.21 it/sec | loss 5.4144\u001b[0m\n",
            "[\u001b[36m11-28 13:48:32\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 6 | loss=5.4046 | duration=218.8447\u001b[0m\n",
            "[\u001b[36m11-28 13:49:02\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 2/11 | 0.10 it/sec | loss 5.6240\u001b[0m\n",
            "[\u001b[36m11-28 13:49:07\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 4/11 | 0.14 it/sec | loss 5.6362\u001b[0m\n",
            "[\u001b[36m11-28 13:49:19\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 6/11 | 0.15 it/sec | loss 5.6412\u001b[0m\n",
            "[\u001b[36m11-28 13:49:25\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 8/11 | 0.17 it/sec | loss 5.6351\u001b[0m\n",
            "[\u001b[36m11-28 13:49:32\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 10/11 | 0.18 it/sec | loss 5.6287\u001b[0m\n",
            "[\u001b[36m11-28 13:49:32\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 6 | loss=5.6287 | duration=60.2362\u001b[0m\n",
            "[\u001b[36m11-28 13:49:32\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 13:50:38\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 9/47 | 0.15 it/sec | loss 5.3347\u001b[0m\n",
            "[\u001b[36m11-28 13:51:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 18/47 | 0.18 it/sec | loss 5.3583\u001b[0m\n",
            "[\u001b[36m11-28 13:51:55\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 27/47 | 0.20 it/sec | loss 5.3716\u001b[0m\n",
            "[\u001b[36m11-28 13:52:31\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 36/47 | 0.21 it/sec | loss 5.3660\u001b[0m\n",
            "[\u001b[36m11-28 13:53:04\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 45/47 | 0.22 it/sec | loss 5.3619\u001b[0m\n",
            "[\u001b[36m11-28 13:53:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 7 | loss=5.3517 | duration=213.3801\u001b[0m\n",
            "[\u001b[36m11-28 13:53:42\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 2/11 | 11.8 sec/it | loss 5.6832\u001b[0m\n",
            "[\u001b[36m11-28 13:53:47\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 4/11 | 0.12 it/sec | loss 5.6901\u001b[0m\n",
            "[\u001b[36m11-28 13:53:57\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 6/11 | 0.14 it/sec | loss 5.6827\u001b[0m\n",
            "[\u001b[36m11-28 13:54:01\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 8/11 | 0.16 it/sec | loss 5.6872\u001b[0m\n",
            "[\u001b[36m11-28 13:54:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 10/11 | 0.19 it/sec | loss 5.6746\u001b[0m\n",
            "[\u001b[36m11-28 13:54:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 7 | loss=5.6746 | duration=59.8593\u001b[0m\n",
            "[\u001b[36m11-28 13:54:06\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 13:55:13\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 9/47 | 0.15 it/sec | loss 5.2867\u001b[0m\n",
            "[\u001b[36m11-28 13:55:50\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 18/47 | 0.18 it/sec | loss 5.2843\u001b[0m\n",
            "[\u001b[36m11-28 13:56:27\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 27/47 | 0.20 it/sec | loss 5.3010\u001b[0m\n",
            "[\u001b[36m11-28 13:57:08\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 36/47 | 0.20 it/sec | loss 5.2968\u001b[0m\n",
            "[\u001b[36m11-28 13:57:40\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 45/47 | 0.22 it/sec | loss 5.2935\u001b[0m\n",
            "[\u001b[36m11-28 13:57:42\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 8 | loss=5.2814 | duration=216.0943\u001b[0m\n",
            "[\u001b[36m11-28 13:58:14\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 2/11 | 10.5 sec/it | loss 5.6858\u001b[0m\n",
            "[\u001b[36m11-28 13:58:21\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 4/11 | 0.13 it/sec | loss 5.6921\u001b[0m\n",
            "[\u001b[36m11-28 13:58:31\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 6/11 | 0.14 it/sec | loss 5.7050\u001b[0m\n",
            "[\u001b[36m11-28 13:58:36\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 8/11 | 0.17 it/sec | loss 5.6984\u001b[0m\n",
            "[\u001b[36m11-28 13:58:40\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 10/11 | 0.19 it/sec | loss 5.6935\u001b[0m\n",
            "[\u001b[36m11-28 13:58:40\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 8 | loss=5.6935 | duration=57.8662\u001b[0m\n",
            "[\u001b[36m11-28 13:58:40\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 13:59:44\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 9/47 | 0.16 it/sec | loss 5.1537\u001b[0m\n",
            "[\u001b[36m11-28 14:00:28\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 18/47 | 0.18 it/sec | loss 5.1810\u001b[0m\n",
            "[\u001b[36m11-28 14:01:09\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 27/47 | 0.19 it/sec | loss 5.1863\u001b[0m\n",
            "[\u001b[36m11-28 14:01:48\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 36/47 | 0.20 it/sec | loss 5.1965\u001b[0m\n",
            "[\u001b[36m11-28 14:02:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 45/47 | 0.21 it/sec | loss 5.1972\u001b[0m\n",
            "[\u001b[36m11-28 14:02:18\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 9 | loss=5.1840 | duration=217.8531\u001b[0m\n",
            "[\u001b[36m11-28 14:02:57\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 2/11 | 12.6 sec/it | loss 5.7570\u001b[0m\n",
            "[\u001b[36m11-28 14:03:01\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 4/11 | 0.12 it/sec | loss 5.7276\u001b[0m\n",
            "[\u001b[36m11-28 14:03:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 6/11 | 0.13 it/sec | loss 5.7103\u001b[0m\n",
            "[\u001b[36m11-28 14:03:15\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 8/11 | 0.16 it/sec | loss 5.6952\u001b[0m\n",
            "[\u001b[36m11-28 14:03:23\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 10/11 | 0.17 it/sec | loss 5.6911\u001b[0m\n",
            "[\u001b[36m11-28 14:03:23\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 9 | loss=5.6911 | duration=64.7955\u001b[0m\n",
            "[\u001b[36m11-28 14:03:23\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 14:04:26\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 9/47 | 0.16 it/sec | loss 5.0922\u001b[0m\n",
            "[\u001b[36m11-28 14:05:13\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 18/47 | 0.17 it/sec | loss 5.0633\u001b[0m\n",
            "[\u001b[36m11-28 14:05:56\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 27/47 | 0.18 it/sec | loss 5.0403\u001b[0m\n",
            "[\u001b[36m11-28 14:06:33\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 36/47 | 0.20 it/sec | loss 5.0431\u001b[0m\n",
            "[\u001b[36m11-28 14:07:00\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 45/47 | 0.21 it/sec | loss 5.0384\u001b[0m\n",
            "[\u001b[36m11-28 14:07:02\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 10 | loss=5.0286 | duration=218.2403\u001b[0m\n",
            "[\u001b[36m11-28 14:07:26\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 2/11 | 0.12 it/sec | loss 5.7960\u001b[0m\n",
            "[\u001b[36m11-28 14:07:34\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 4/11 | 0.16 it/sec | loss 5.8079\u001b[0m\n",
            "[\u001b[36m11-28 14:07:46\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 6/11 | 0.16 it/sec | loss 5.8278\u001b[0m\n",
            "[\u001b[36m11-28 14:07:50\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 8/11 | 0.19 it/sec | loss 5.8277\u001b[0m\n",
            "[\u001b[36m11-28 14:07:56\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 10/11 | 0.20 it/sec | loss 5.8121\u001b[0m\n",
            "[\u001b[36m11-28 14:07:57\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 10 | loss=5.8121 | duration=54.7931\u001b[0m\n",
            "[\u001b[36m11-28 14:07:57\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 14:09:00\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 9/47 | 0.16 it/sec | loss 4.9444\u001b[0m\n",
            "[\u001b[36m11-28 14:09:39\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 18/47 | 0.19 it/sec | loss 4.9244\u001b[0m\n",
            "[\u001b[36m11-28 14:10:17\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 27/47 | 0.20 it/sec | loss 4.9438\u001b[0m\n",
            "[\u001b[36m11-28 14:10:56\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 36/47 | 0.21 it/sec | loss 4.9330\u001b[0m\n",
            "[\u001b[36m11-28 14:11:25\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 45/47 | 0.22 it/sec | loss 4.9263\u001b[0m\n",
            "[\u001b[36m11-28 14:11:27\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 11 | loss=4.9198 | duration=210.3528\u001b[0m\n",
            "[\u001b[36m11-28 14:11:55\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 2/11 | 0.11 it/sec | loss 6.0102\u001b[0m\n",
            "[\u001b[36m11-28 14:11:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 4/11 | 0.16 it/sec | loss 5.9757\u001b[0m\n",
            "[\u001b[36m11-28 14:12:10\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 6/11 | 0.17 it/sec | loss 5.9672\u001b[0m\n",
            "[\u001b[36m11-28 14:12:17\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 8/11 | 0.18 it/sec | loss 5.9647\u001b[0m\n",
            "[\u001b[36m11-28 14:12:21\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 10/11 | 0.20 it/sec | loss 5.9600\u001b[0m\n",
            "[\u001b[36m11-28 14:12:21\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 11 | loss=5.9600 | duration=54.1080\u001b[0m\n",
            "[\u001b[36m11-28 14:12:21\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 14:13:20\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 9/47 | 0.17 it/sec | loss 4.6755\u001b[0m\n",
            "[\u001b[36m11-28 14:14:04\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 18/47 | 0.19 it/sec | loss 4.6857\u001b[0m\n",
            "[\u001b[36m11-28 14:14:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 27/47 | 0.20 it/sec | loss 4.6632\u001b[0m\n",
            "[\u001b[36m11-28 14:15:24\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 36/47 | 0.20 it/sec | loss 4.6509\u001b[0m\n",
            "[\u001b[36m11-28 14:15:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 45/47 | 0.22 it/sec | loss 4.6228\u001b[0m\n",
            "[\u001b[36m11-28 14:15:54\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 12 | loss=4.6132 | duration=212.1403\u001b[0m\n",
            "[\u001b[36m11-28 14:16:29\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 2/11 | 11.5 sec/it | loss 6.1177\u001b[0m\n",
            "[\u001b[36m11-28 14:16:35\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 4/11 | 0.12 it/sec | loss 6.1888\u001b[0m\n",
            "[\u001b[36m11-28 14:16:41\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 6/11 | 0.15 it/sec | loss 6.1857\u001b[0m\n",
            "[\u001b[36m11-28 14:16:45\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 8/11 | 0.18 it/sec | loss 6.1822\u001b[0m\n",
            "[\u001b[36m11-28 14:16:53\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 10/11 | 0.19 it/sec | loss 6.1651\u001b[0m\n",
            "[\u001b[36m11-28 14:16:53\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 12 | loss=6.1651 | duration=59.1933\u001b[0m\n",
            "[\u001b[36m11-28 14:16:53\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-28 14:17:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 13 | 9/47 | 0.15 it/sec | loss 4.3431\u001b[0m\n",
            "[\u001b[36m11-28 14:18:38\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 13 | 18/47 | 0.18 it/sec | loss 4.3032\u001b[0m\n",
            "[\u001b[36m11-28 14:19:20\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 13 | 27/47 | 0.19 it/sec | loss 4.2891\u001b[0m\n",
            "[\u001b[36m11-28 14:19:54\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 13 | 36/47 | 0.20 it/sec | loss 4.2588\u001b[0m\n",
            "[\u001b[36m11-28 14:20:23\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 13 | 45/47 | 0.22 it/sec | loss 4.2458\u001b[0m\n",
            "[\u001b[36m11-28 14:20:25\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 13 | loss=4.2313 | duration=211.5649\u001b[0m\n",
            "[\u001b[36m11-28 14:21:01\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 13 | 2/11 | 12.0 sec/it | loss 6.4066\u001b[0m\n",
            "[\u001b[36m11-28 14:21:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 13 | 4/11 | 0.12 it/sec | loss 6.4085\u001b[0m\n",
            "[\u001b[36m11-28 14:21:14\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 13 | 6/11 | 0.14 it/sec | loss 6.4246\u001b[0m\n",
            "[\u001b[36m11-28 14:21:18\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 13 | 8/11 | 0.17 it/sec | loss 6.4162\u001b[0m\n",
            "[\u001b[36m11-28 14:21:26\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 13 | 10/11 | 0.18 it/sec | loss 6.4159\u001b[0m\n",
            "[\u001b[36m11-28 14:21:26\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 13 | loss=6.4159 | duration=61.0051\u001b[0m\n",
            "[\u001b[36m11-28 14:21:26\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[33mWARNING\u001b[0m] - Model valid_loss did not improve for 10 epochs. Stopping the training.\u001b[0m\n",
            "[\u001b[36m11-28 14:21:26\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "\u001b[1mExecutor:\u001b[0m All workers completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd brainmagick && python -m scripts.run_eval_probs grid_name=\"mygrid\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yVwGZMb29Qd",
        "outputId": "e047cd27-a1b8-4922-b3e0-5dd5f6b7440e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-28 14:34:05.868165: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 14:34:05.868222: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 14:34:05.868260: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 14:34:05.876245: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-28 14:34:06.993714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Hostname 6ba44a4dd73e not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "Running eval on 1 signatures: ['f2870bd1']\n",
            "        saving to /content/brainmagick/outputs/eval/signatures\n",
            "[\u001b[36m11-28 14:34:11\u001b[0m][\u001b[34mbm.play\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading solver from XP f2870bd1. Overrides used: ['norm.max_scale=20', 'dset.n_recordings=15', 'dset.selections=[\"brennan2019\"]']\u001b[0m\n",
            "[\u001b[36m11-28 14:34:11\u001b[0m][\u001b[34mbm._env\u001b[0m][\u001b[33mWARNING\u001b[0m] - Hostname 6ba44a4dd73e not defined in /conf/study_paths/study_paths.yaml. Using default paths.\u001b[0m\n",
            "[\u001b[36m11-28 14:34:12\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 3/15 | 7.01 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:12\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 6/15 | 8.20 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:13\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 9/15 | 8.83 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:13\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 12/15 | 9.16 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:13\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - # Examples (train | valid | test): 11934 | 2800 | 2846\u001b[0m\n",
            "[\u001b[36m11-28 14:34:16\u001b[0m][\u001b[34mbm.train\u001b[0m][\u001b[32mINFO\u001b[0m] - Model hash: e1c1845dd7505b632ae3cc169ac842f06cef5aad\u001b[0m\n",
            "[\u001b[36m11-28 14:34:16\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - test studies: ['brennan2019']\u001b[0m\n",
            "[\u001b[36m11-28 14:34:16\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Running Evaluation on selected test dataset None in /content/brainmagick/outputs/eval/signatures/f2870bd1/metadata.csv\u001b[0m\n",
            "[\u001b[36m11-28 14:34:16\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Extracting test data\u001b[0m\n",
            "[\u001b[36m11-28 14:34:31\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 1/29 | 0.13 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:33\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 2/29 | 0.18 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:34\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 3/29 | 0.22 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:36\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 4/29 | 0.26 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:37\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 5/29 | 0.29 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:38\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 6/29 | 0.32 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:40\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 7/29 | 0.34 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:42\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 8/29 | 0.36 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:44\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 9/29 | 0.37 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:45\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 10/29 | 0.38 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:47\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 11/29 | 0.39 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:49\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 12/29 | 0.40 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:51\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 13/29 | 0.41 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:53\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 14/29 | 0.41 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:55\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 15/29 | 0.42 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:57\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 16/29 | 0.42 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:34:59\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 17/29 | 0.43 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:01\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 18/29 | 0.43 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:02\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 19/29 | 0.44 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:03\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 20/29 | 0.45 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:05\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 21/29 | 0.46 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:06\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 22/29 | 0.47 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:07\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 23/29 | 0.48 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:08\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 24/29 | 0.49 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:09\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 25/29 | 0.49 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:10\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 26/29 | 0.50 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:11\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 27/29 | 0.51 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:12\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - extract | 28/29 | 0.53 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:13\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Compute probabilities\u001b[0m\n",
            "[\u001b[36m11-28 14:35:13\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Saving config output to /content/brainmagick/outputs/eval/signatures/f2870bd1\u001b[0m\n",
            "[\u001b[36m11-28 14:35:13\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Compute probabilities for segments\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - probs | 1/3 | 1.77 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - probs | 2/3 | 1.82 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Saving probs output to /content/brainmagick/outputs/eval/signatures/f2870bd1\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Saving metadata output to /content/brainmagick/outputs/eval/signatures/f2870bd1\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Compute accuracies\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Top-1 acc: 0.53\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Top-5 acc: 3.20\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Top-10 acc: 5.80\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Saving acc output to /content/brainmagick/outputs/eval/signatures/f2870bd1\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - n_test_samples: 2846\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - n_test_vocab: 126\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - n_test_segments: 190\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - n_neg_samples: 2846\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - n_neg_segments: 190\u001b[0m\n",
            "[\u001b[36m11-28 14:35:14\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - Saving stats output to /content/brainmagick/outputs/eval/signatures/f2870bd1\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ignore the rest"
      ],
      "metadata": {
        "id": "j_odb56oTBo9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vddSbiCXiYPz",
        "outputId": "31d79c29-14f4-4d83-942f-1d4e547bd6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hostname 6ba44a4dd73e not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "2023-11-28 11:30:04.275582: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 11:30:04.275647: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 11:30:04.275678: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 11:30:04.283719: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-28 11:30:05.267660: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
            "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
            "  ret = run_job(\n",
            "[2023-11-28 11:30:08,794][bm._env][WARNING] - Hostname 6ba44a4dd73e not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "[2023-11-28 11:30:08,803][bm.train][INFO] - For logs, checkpoints and samples, check /content/brainmagick/outputs/xps/a871e92b.\n",
            "[2023-11-28 11:30:08,803][bm.train][INFO] - Caching intermediate data under /content/brainmagick/cache.\n",
            "[\u001b[36m11-28 11:30:08\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
            "Downloading `brennan2019` files to /content/brainmagick/data/brennan2019/download...\n",
            "100% 56/56 [09:04<00:00,  9.72s/it]\n",
            "Extracting `brennan2019` audio to /content/brainmagick/data/brennan2019/download/audio...\n",
            "Extracting `brennan2019` proc to /content/brainmagick/data/brennan2019/download/proc...\n",
            "[\u001b[36m11-28 11:39:22\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 1/4 | 5.45 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 11:39:22\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 2/4 | 6.48 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 11:39:22\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 3/4 | 7.16 it/sec\u001b[0m\n",
            "[\u001b[36m11-28 11:39:22\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - # Examples (train | valid | test): 3194 | 743 | 758\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!cd brainmagick && HYDRA_FULL_ERROR=1 dora run download_only=True 'dset.selections=[brennan2019]' dset.n_recordings=4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd brainmagick && HYDRA_FULL_ERROR=1 dora grid nmi.main_table --dry_run --init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57NSfRsGM7FP",
        "outputId": "44f13995-43dd-403f-9ac7-963fb29c1dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hostname e4e524eea5bc not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "2023-11-05 11:17:51.743504: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-05 11:17:51.743562: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-05 11:17:51.743601: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-05 11:17:51.764553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-05 11:17:53.861612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Monitoring Grid nmi.main_table\n",
            "Base name:  model=clip_conv\n",
            "\u001b[1m\u001b[0m                                                                     Meta                                                                     | trai | vali |    test  \u001b[0m\u001b[0m\n",
            "\u001b[1m\u001b[38;5;245min  name                                                                                                                   sta       sig  sid | e  l | l  b | wer  wer_\u001b[0m\u001b[0m\n",
            "\u001b[0m 0  dse.force_uid_assignement dse.selections=['audio_mous']                                                                N/A  34219380      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m 1  dse.force_uid_assignement dse.selections=['audio_mous'] opt.epochs=1 opt.max_batches=1 tes.wer_random                  N/A  bcd967bc      | 0    |      |          \u001b[0m\n",
            "\u001b[0m 2  dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous']                                   N/A  029557fd      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m 3  feature_model=deep_mel dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous']            N/A  53f86c17      | 0    |      |          \u001b[0m\n",
            "\u001b[0m 4  dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous'] opt.loss=mse                      N/A  ca882d84      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m 5                                                                                                                         N/A  6e3bf7d7      | 0    |      |          \u001b[0m\n",
            "\u001b[0m 6  opt.epochs=1 opt.max_batches=1 tes.wer_random                                                                          N/A  c5455d58      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m 7  dse.features=['MelSpectrum']                                                                                           N/A  87a001d2      | 0    |      |          \u001b[0m\n",
            "\u001b[0m 8  feature_model=deep_mel dse.features=['MelSpectrum']                                                                    N/A  13767159      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m 9  dse.features=['MelSpectrum'] opt.loss=mse                                                                              N/A  c512a1a6      | 0    |      |          \u001b[0m\n",
            "\u001b[0m10  dse.selections=['broderick2019'] tes.wer_recordings=100                                                                N/A  557f5f8a      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m11  dse.selections=['broderick2019'] opt.epochs=1 opt.max_batches=1 tes.wer_random tes.wer_recordings=100                  N/A  ff8f3a2f      | 0    |      |          \u001b[0m\n",
            "\u001b[0m12  dse.features=['MelSpectrum'] dse.selections=['broderick2019'] tes.wer_recordings=100                                   N/A  a7e4621f      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m13  feature_model=deep_mel dse.features=['MelSpectrum'] dse.selections=['broderick2019'] tes.wer_recordings=100            N/A  8207605c      | 0    |      |          \u001b[0m\n",
            "\u001b[0m14  dse.features=['MelSpectrum'] dse.selections=['broderick2019'] opt.loss=mse tes.wer_recordings=100                      N/A  68c1a1e5      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m15  dse.selections=['brennan2019']                                                                                         N/A  4395629c      | 0    |      |          \u001b[0m\n",
            "\u001b[0m16  dse.selections=['brennan2019'] opt.epochs=1 opt.max_batches=1 tes.wer_random                                           N/A  3b8b933e      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m17  dse.features=['MelSpectrum'] dse.selections=['brennan2019']                                                            N/A  04966af2      | 0    |      |          \u001b[0m\n",
            "\u001b[0m18  feature_model=deep_mel dse.features=['MelSpectrum'] dse.selections=['brennan2019']                                     N/A  765c995a      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m19  dse.features=['MelSpectrum'] dse.selections=['brennan2019'] opt.loss=mse                                               N/A  413c5356      | 0    |      |          \u001b[0m\n",
            "\u001b[0m20  dse.force_uid_assignement dse.selections=['audio_mous'] seed=2037                                                      N/A  59c3fedd      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m21  dse.force_uid_assignement dse.selections=['audio_mous'] opt.epochs=1 opt.max_batches=1 seed=2037 tes.wer_random        N/A  528367b9      | 0    |      |          \u001b[0m\n",
            "\u001b[0m22  dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous'] seed=2037                         N/A  bce54762      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m23  feature_model=deep_mel dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous'] seed=2037  N/A  10815196      | 0    |      |          \u001b[0m\n",
            "\u001b[0m24  dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous'] opt.loss=mse seed=2037            N/A  14e245d9      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m25  seed=2037                                                                                                              N/A  884343d2      | 0    |      |          \u001b[0m\n",
            "\u001b[0m26  opt.epochs=1 opt.max_batches=1 seed=2037 tes.wer_random                                                                N/A  750d6954      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m27  dse.features=['MelSpectrum'] seed=2037                                                                                 N/A  ca0c1506      | 0    |      |          \u001b[0m\n",
            "\u001b[0m28  feature_model=deep_mel dse.features=['MelSpectrum'] seed=2037                                                          N/A  e1a95c9d      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m29  dse.features=['MelSpectrum'] opt.loss=mse seed=2037                                                                    N/A  f1cdb4e1      | 0    |      |          \u001b[0m\n",
            "\u001b[0m30  dse.selections=['broderick2019'] seed=2037 tes.wer_recordings=100                                                      N/A  adc8346b      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m31  dse.selections=['broderick2019'] opt.epochs=1 opt.max_batches=1 seed=2037 tes.wer_random tes.wer_recordings=100        N/A  69712ead      | 0    |      |          \u001b[0m\n",
            "\u001b[0m32  dse.features=['MelSpectrum'] dse.selections=['broderick2019'] seed=2037 tes.wer_recordings=100                         N/A  896a10b2      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m33  feature_model=deep_mel dse.features=['MelSpectrum'] dse.selections=['broderick2019'] seed=2037 tes.wer_recordings=100  N/A  426029bd      | 0    |      |          \u001b[0m\n",
            "\u001b[0m34  dse.features=['MelSpectrum'] dse.selections=['broderick2019'] opt.loss=mse seed=2037 tes.wer_recordings=100            N/A  0edfcb98      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m35  dse.selections=['brennan2019'] seed=2037                                                                               N/A  ba38d581      | 0    |      |          \u001b[0m\n",
            "\u001b[0m36  dse.selections=['brennan2019'] opt.epochs=1 opt.max_batches=1 seed=2037 tes.wer_random                                 N/A  784dae52      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m37  dse.features=['MelSpectrum'] dse.selections=['brennan2019'] seed=2037                                                  N/A  5be341d4      | 0    |      |          \u001b[0m\n",
            "\u001b[0m38  feature_model=deep_mel dse.features=['MelSpectrum'] dse.selections=['brennan2019'] seed=2037                           N/A  0a01dee9      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m39  dse.features=['MelSpectrum'] dse.selections=['brennan2019'] opt.loss=mse seed=2037                                     N/A  9c6ed694      | 0    |      |          \u001b[0m\n",
            "\u001b[0m40  dse.force_uid_assignement dse.selections=['audio_mous'] seed=2038                                                      N/A  b220992a      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m41  dse.force_uid_assignement dse.selections=['audio_mous'] opt.epochs=1 opt.max_batches=1 seed=2038 tes.wer_random        N/A  f6a650ba      | 0    |      |          \u001b[0m\n",
            "\u001b[0m42  dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous'] seed=2038                         N/A  48b35a15      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m43  feature_model=deep_mel dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous'] seed=2038  N/A  365153df      | 0    |      |          \u001b[0m\n",
            "\u001b[0m44  dse.features=['MelSpectrum'] dse.force_uid_assignement dse.selections=['audio_mous'] opt.loss=mse seed=2038            N/A  c8968f15      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m45  seed=2038                                                                                                              N/A  d977efac      | 0    |      |          \u001b[0m\n",
            "\u001b[0m46  opt.epochs=1 opt.max_batches=1 seed=2038 tes.wer_random                                                                N/A  49b468a5      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m47  dse.features=['MelSpectrum'] seed=2038                                                                                 N/A  71007c6f      | 0    |      |          \u001b[0m\n",
            "\u001b[0m48  feature_model=deep_mel dse.features=['MelSpectrum'] seed=2038                                                          N/A  2c768010      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m49  dse.features=['MelSpectrum'] opt.loss=mse seed=2038                                                                    N/A  6bc9ab43      | 0    |      |          \u001b[0m\n",
            "\u001b[0m50  dse.selections=['broderick2019'] seed=2038 tes.wer_recordings=100                                                      N/A  a7028f25      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m51  dse.selections=['broderick2019'] opt.epochs=1 opt.max_batches=1 seed=2038 tes.wer_random tes.wer_recordings=100        N/A  813077f4      | 0    |      |          \u001b[0m\n",
            "\u001b[0m52  dse.features=['MelSpectrum'] dse.selections=['broderick2019'] seed=2038 tes.wer_recordings=100                         N/A  3d97b459      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m53  feature_model=deep_mel dse.features=['MelSpectrum'] dse.selections=['broderick2019'] seed=2038 tes.wer_recordings=100  N/A  5b8e222b      | 0    |      |          \u001b[0m\n",
            "\u001b[0m54  dse.features=['MelSpectrum'] dse.selections=['broderick2019'] opt.loss=mse seed=2038 tes.wer_recordings=100            N/A  868b0132      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m55  dse.selections=['brennan2019'] seed=2038                                                                               N/A  5dcd85a2      | 0    |      |          \u001b[0m\n",
            "\u001b[0m56  dse.selections=['brennan2019'] opt.epochs=1 opt.max_batches=1 seed=2038 tes.wer_random                                 N/A  471a79d9      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m57  dse.features=['MelSpectrum'] dse.selections=['brennan2019'] seed=2038                                                  N/A  34f042ed      | 0    |      |          \u001b[0m\n",
            "\u001b[0m58  feature_model=deep_mel dse.features=['MelSpectrum'] dse.selections=['brennan2019'] seed=2038                           N/A  2fe8bdbf      | 0    |      |          \u001b[0m\n",
            "\u001b[38;5;245m59  dse.features=['MelSpectrum'] dse.selections=['brennan2019'] opt.loss=mse seed=2038                                     N/A  dc2a44b8      | 0    |      |          \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd brainmagick && HYDRA_FULL_ERROR=1 dora run 'dset.selections=[brennan2019]' dset.n_recordings=20 -d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRkOjGmkNXDu",
        "outputId": "1b78a2c0-2118-430e-b1fe-01fddd41cca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hostname abe28bf11dde not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "2023-11-08 06:24:27.086862: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-08 06:24:27.086923: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-08 06:24:27.086950: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-08 06:24:27.096434: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-08 06:24:28.948017: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1mExecutor:\u001b[0m Starting 1 worker processes for DDP.\n",
            "Hostname abe28bf11dde not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "2023-11-08 06:24:37.261682: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-08 06:24:37.261739: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-08 06:24:37.261763: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-08 06:24:38.315574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
            "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
            "  ret = run_job(\n",
            "[2023-11-08 06:24:41,103][bm._env][WARNING] - Hostname abe28bf11dde not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
            "[2023-11-08 06:24:41,112][bm.train][INFO] - For logs, checkpoints and samples, check /content/brainmagick/outputs/xps/9d3a672f.\n",
            "[2023-11-08 06:24:41,112][bm.train][INFO] - Caching intermediate data under /content/brainmagick/cache.\n",
            "[\u001b[36m11-08 06:24:41\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
            "[\u001b[36m11-08 06:24:59\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 4/20 | 7.17 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:24:59\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 8/20 | 8.22 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:24:59\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 12/20 | 8.74 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:25:00\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading Subjects | 16/20 | 9.07 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:25:00\u001b[0m][\u001b[34mbm.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - # Examples (train | valid | test): 15938 | 3728 | 3797\u001b[0m\n",
            "[\u001b[36m11-08 06:25:01\u001b[0m][\u001b[34mbm.train\u001b[0m][\u001b[32mINFO\u001b[0m] - Model hash: 785fadb9762536b72e9ac880af8382ac5efdfefe\u001b[0m\n",
            "[\u001b[36m11-08 06:25:02\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scaler. Dataset size=15938 samples.\u001b[0m\n",
            "[\u001b[36m11-08 06:25:52\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scalers | 4/20 | 10.0 sec/it\u001b[0m\n",
            "[\u001b[36m11-08 06:26:43\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scalers | 8/20 | 11.3 sec/it\u001b[0m\n",
            "[\u001b[36m11-08 06:27:35\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scalers | 12/20 | 11.8 sec/it\u001b[0m\n",
            "[\u001b[36m11-08 06:28:23\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - Fitting scalers | 16/20 | 11.9 sec/it\u001b[0m\n",
            "[\u001b[36m11-08 06:29:26\u001b[0m][\u001b[34mbm.norm\u001b[0m][\u001b[32mINFO\u001b[0m] - features collected for norm: torch.Size([1848320, 1024])\u001b[0m\n",
            "[\u001b[36m11-08 06:30:40\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scaler cache file /content/brainmagick/cache/scaler/37483796bce6ae2a/bf21a9e8fbc5a384.pkl\u001b[0m\n",
            "[\u001b[36m11-08 06:31:50\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 12/63 | 0.19 it/sec | loss 5.5986\u001b[0m\n",
            "[\u001b[36m11-08 06:32:33\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 24/63 | 0.22 it/sec | loss 5.5836\u001b[0m\n",
            "[\u001b[36m11-08 06:33:32\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 36/63 | 0.21 it/sec | loss 5.5760\u001b[0m\n",
            "[\u001b[36m11-08 06:34:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 48/63 | 0.23 it/sec | loss 5.5732\u001b[0m\n",
            "[\u001b[36m11-08 06:35:05\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 60/63 | 0.23 it/sec | loss 5.5694\u001b[0m\n",
            "[\u001b[36m11-08 06:35:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 1 | loss=5.5478 | duration=266.2664\u001b[0m\n",
            "[\u001b[36m11-08 06:37:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 3/15 | 39.1 sec/it | loss 5.5747\u001b[0m\n",
            "[\u001b[36m11-08 06:37:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 6/15 | 22.5 sec/it | loss 5.5733\u001b[0m\n",
            "[\u001b[36m11-08 06:37:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 9/15 | 17.3 sec/it | loss 5.5849\u001b[0m\n",
            "[\u001b[36m11-08 06:38:14\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 12/15 | 14.5 sec/it | loss 5.5837\u001b[0m\n",
            "[\u001b[36m11-08 06:38:15\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 5.5532\u001b[0m\n",
            "[\u001b[36m11-08 06:38:15\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 1 | loss=5.5532 | duration=188.9628\u001b[0m\n",
            "[\u001b[36m11-08 06:39:53\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 3/15 | 24.5 sec/it\u001b[0m\n",
            "[\u001b[36m11-08 06:40:09\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 6/15 | 16.3 sec/it\u001b[0m\n",
            "[\u001b[36m11-08 06:40:21\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 9/15 | 12.5 sec/it\u001b[0m\n",
            "[\u001b[36m11-08 06:40:35\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 12/15 | 10.8 sec/it\u001b[0m\n",
            "[\u001b[36m11-08 06:40:48\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - wer 3797 negatives selected\u001b[0m\n",
            "[\u001b[36m11-08 06:41:00\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 759/3797 | 71.48 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:41:11\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 1518/3797 | 71.93 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:41:21\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 2277/3797 | 72.02 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:41:32\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 3036/3797 | 72.02 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:41:42\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 3795/3797 | 72.02 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:41:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTest Summary | Epoch 1 | wer=99.210% | wer_vocab=70.187% | duration=208.2298\u001b[0m\n",
            "[\u001b[36m11-08 06:41:43\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 06:42:54\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 12/63 | 0.18 it/sec | loss 5.5330\u001b[0m\n",
            "[\u001b[36m11-08 06:43:35\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 24/63 | 0.22 it/sec | loss 5.5351\u001b[0m\n",
            "[\u001b[36m11-08 06:44:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 36/63 | 0.21 it/sec | loss 5.5345\u001b[0m\n",
            "[\u001b[36m11-08 06:45:20\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 48/63 | 0.23 it/sec | loss 5.5295\u001b[0m\n",
            "[\u001b[36m11-08 06:46:10\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 60/63 | 0.23 it/sec | loss 5.5273\u001b[0m\n",
            "[\u001b[36m11-08 06:46:17\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 2 | loss=5.5045 | duration=273.3085\u001b[0m\n",
            "[\u001b[36m11-08 06:46:47\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 3/15 | 0.14 it/sec | loss 5.5791\u001b[0m\n",
            "[\u001b[36m11-08 06:47:12\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 6/15 | 0.13 it/sec | loss 5.5762\u001b[0m\n",
            "[\u001b[36m11-08 06:47:13\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 9/15 | 0.18 it/sec | loss 5.5806\u001b[0m\n",
            "[\u001b[36m11-08 06:47:28\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 12/15 | 0.18 it/sec | loss 5.5831\u001b[0m\n",
            "[\u001b[36m11-08 06:47:29\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 5.5408\u001b[0m\n",
            "[\u001b[36m11-08 06:47:29\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 2 | loss=5.5408 | duration=71.9630\u001b[0m\n",
            "[\u001b[36m11-08 06:48:03\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 3/15 | 0.12 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:48:28\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 6/15 | 0.12 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:48:31\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 9/15 | 0.16 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:48:45\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER | 12/15 | 0.17 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:48:58\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - wer 3797 negatives selected\u001b[0m\n",
            "[\u001b[36m11-08 06:49:10\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 759/3797 | 72.44 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:49:20\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 1518/3797 | 72.38 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:49:31\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 2277/3797 | 72.36 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:49:41\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 3036/3797 | 72.30 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:49:52\u001b[0m][\u001b[34mbm.wer\u001b[0m][\u001b[32mINFO\u001b[0m] - WER Rank | 3795/3797 | 72.27 it/sec\u001b[0m\n",
            "[\u001b[36m11-08 06:49:53\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTest Summary | Epoch 2 | wer=98.604% | wer_vocab=72.347% | duration=143.8330\u001b[0m\n",
            "[\u001b[36m11-08 06:49:53\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 06:51:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 12/63 | 0.17 it/sec | loss 5.5060\u001b[0m\n",
            "[\u001b[36m11-08 06:51:53\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 24/63 | 0.21 it/sec | loss 5.4945\u001b[0m\n",
            "[\u001b[36m11-08 06:52:44\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 36/63 | 0.22 it/sec | loss 5.4958\u001b[0m\n",
            "[\u001b[36m11-08 06:53:41\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 48/63 | 0.22 it/sec | loss 5.4909\u001b[0m\n",
            "[\u001b[36m11-08 06:54:18\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 60/63 | 0.23 it/sec | loss 5.4849\u001b[0m\n",
            "[\u001b[36m11-08 06:54:20\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 3 | loss=5.4615 | duration=267.0157\u001b[0m\n",
            "[\u001b[36m11-08 06:54:50\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/15 | 0.14 it/sec | loss 5.6206\u001b[0m\n",
            "[\u001b[36m11-08 06:55:17\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/15 | 0.12 it/sec | loss 5.6224\u001b[0m\n",
            "[\u001b[36m11-08 06:55:17\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/15 | 0.17 it/sec | loss 5.6184\u001b[0m\n",
            "[\u001b[36m11-08 06:55:33\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/15 | 0.18 it/sec | loss 5.6174\u001b[0m\n",
            "[\u001b[36m11-08 06:55:34\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 3 | loss=5.5781 | duration=73.9384\u001b[0m\n",
            "[\u001b[36m11-08 06:55:34\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 06:56:40\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 12/63 | 0.20 it/sec | loss 5.4079\u001b[0m\n",
            "[\u001b[36m11-08 06:57:34\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 24/63 | 0.21 it/sec | loss 5.3972\u001b[0m\n",
            "[\u001b[36m11-08 06:58:32\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 36/63 | 0.21 it/sec | loss 5.3899\u001b[0m\n",
            "[\u001b[36m11-08 06:59:15\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 48/63 | 0.22 it/sec | loss 5.3721\u001b[0m\n",
            "[\u001b[36m11-08 06:59:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 60/63 | 0.23 it/sec | loss 5.3589\u001b[0m\n",
            "[\u001b[36m11-08 07:00:13\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 4 | loss=5.3331 | duration=278.6552\u001b[0m\n",
            "[\u001b[36m11-08 07:00:42\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/15 | 0.14 it/sec | loss 5.5842\u001b[0m\n",
            "[\u001b[36m11-08 07:00:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/15 | 0.18 it/sec | loss 5.5806\u001b[0m\n",
            "[\u001b[36m11-08 07:01:10\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/15 | 0.17 it/sec | loss 5.5865\u001b[0m\n",
            "[\u001b[36m11-08 07:01:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/15 | 0.21 it/sec | loss 5.5893\u001b[0m\n",
            "[\u001b[36m11-08 07:01:27\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 4 | loss=5.5476 | duration=73.6159\u001b[0m\n",
            "[\u001b[36m11-08 07:01:27\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 07:02:47\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 12/63 | 0.16 it/sec | loss 5.1730\u001b[0m\n",
            "[\u001b[36m11-08 07:03:25\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 24/63 | 0.21 it/sec | loss 5.1522\u001b[0m\n",
            "[\u001b[36m11-08 07:04:28\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 36/63 | 0.20 it/sec | loss 5.1181\u001b[0m\n",
            "[\u001b[36m11-08 07:05:15\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 48/63 | 0.21 it/sec | loss 5.0671\u001b[0m\n",
            "[\u001b[36m11-08 07:06:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 60/63 | 0.22 it/sec | loss 5.0308\u001b[0m\n",
            "[\u001b[36m11-08 07:06:07\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 5 | loss=5.0039 | duration=280.0151\u001b[0m\n",
            "[\u001b[36m11-08 07:06:36\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/15 | 0.14 it/sec | loss 5.6611\u001b[0m\n",
            "[\u001b[36m11-08 07:06:46\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/15 | 0.18 it/sec | loss 5.6535\u001b[0m\n",
            "[\u001b[36m11-08 07:06:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/15 | 0.19 it/sec | loss 5.6348\u001b[0m\n",
            "[\u001b[36m11-08 07:07:09\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/15 | 0.21 it/sec | loss 5.6495\u001b[0m\n",
            "[\u001b[36m11-08 07:07:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 5 | loss=5.6027 | duration=68.5483\u001b[0m\n",
            "[\u001b[36m11-08 07:07:16\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 07:08:19\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 12/63 | 0.21 it/sec | loss 4.6637\u001b[0m\n",
            "[\u001b[36m11-08 07:09:17\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 24/63 | 0.21 it/sec | loss 4.5930\u001b[0m\n",
            "[\u001b[36m11-08 07:09:57\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 36/63 | 0.23 it/sec | loss 4.5532\u001b[0m\n",
            "[\u001b[36m11-08 07:10:58\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 48/63 | 0.22 it/sec | loss 4.5203\u001b[0m\n",
            "[\u001b[36m11-08 07:11:40\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 6 | 60/63 | 0.23 it/sec | loss 4.4889\u001b[0m\n",
            "[\u001b[36m11-08 07:11:44\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 6 | loss=4.4631 | duration=267.5329\u001b[0m\n",
            "[\u001b[36m11-08 07:12:07\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 3/15 | 0.17 it/sec | loss 5.8143\u001b[0m\n",
            "[\u001b[36m11-08 07:12:26\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 6/15 | 0.17 it/sec | loss 5.7858\u001b[0m\n",
            "[\u001b[36m11-08 07:12:37\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 9/15 | 0.19 it/sec | loss 5.7810\u001b[0m\n",
            "[\u001b[36m11-08 07:12:48\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 6 | 12/15 | 0.20 it/sec | loss 5.7592\u001b[0m\n",
            "[\u001b[36m11-08 07:12:49\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 6 | loss=5.7176 | duration=65.3964\u001b[0m\n",
            "[\u001b[36m11-08 07:12:49\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 07:13:56\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 12/63 | 0.19 it/sec | loss 4.0172\u001b[0m\n",
            "[\u001b[36m11-08 07:14:48\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 24/63 | 0.21 it/sec | loss 3.9878\u001b[0m\n",
            "[\u001b[36m11-08 07:15:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 36/63 | 0.21 it/sec | loss 3.9776\u001b[0m\n",
            "[\u001b[36m11-08 07:16:30\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 48/63 | 0.22 it/sec | loss 4.0344\u001b[0m\n",
            "[\u001b[36m11-08 07:17:10\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 7 | 60/63 | 0.23 it/sec | loss 4.0599\u001b[0m\n",
            "[\u001b[36m11-08 07:17:24\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 7 | loss=4.0349 | duration=274.5786\u001b[0m\n",
            "[\u001b[36m11-08 07:17:55\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 3/15 | 0.13 it/sec | loss 6.0111\u001b[0m\n",
            "[\u001b[36m11-08 07:18:19\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 6/15 | 0.13 it/sec | loss 5.9363\u001b[0m\n",
            "[\u001b[36m11-08 07:18:20\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 9/15 | 0.18 it/sec | loss 5.9330\u001b[0m\n",
            "[\u001b[36m11-08 07:18:36\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 7 | 12/15 | 0.18 it/sec | loss 5.9311\u001b[0m\n",
            "[\u001b[36m11-08 07:18:37\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 7 | loss=5.8940 | duration=73.0603\u001b[0m\n",
            "[\u001b[36m11-08 07:18:37\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 07:19:47\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 12/63 | 0.19 it/sec | loss 3.7920\u001b[0m\n",
            "[\u001b[36m11-08 07:20:31\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 24/63 | 0.22 it/sec | loss 3.7641\u001b[0m\n",
            "[\u001b[36m11-08 07:21:33\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 36/63 | 0.21 it/sec | loss 3.7131\u001b[0m\n",
            "[\u001b[36m11-08 07:22:22\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 48/63 | 0.22 it/sec | loss 3.6373\u001b[0m\n",
            "[\u001b[36m11-08 07:23:03\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 8 | 60/63 | 0.23 it/sec | loss 3.5808\u001b[0m\n",
            "[\u001b[36m11-08 07:23:05\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 8 | loss=3.5540 | duration=267.7237\u001b[0m\n",
            "[\u001b[36m11-08 07:23:34\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 3/15 | 0.14 it/sec | loss 6.3449\u001b[0m\n",
            "[\u001b[36m11-08 07:23:58\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 6/15 | 0.13 it/sec | loss 6.2883\u001b[0m\n",
            "[\u001b[36m11-08 07:23:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 9/15 | 0.19 it/sec | loss 6.3360\u001b[0m\n",
            "[\u001b[36m11-08 07:24:15\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 8 | 12/15 | 0.19 it/sec | loss 6.3229\u001b[0m\n",
            "[\u001b[36m11-08 07:24:15\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 8 | loss=6.2732 | duration=70.0657\u001b[0m\n",
            "[\u001b[36m11-08 07:24:15\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 07:25:24\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 12/63 | 0.19 it/sec | loss 2.9075\u001b[0m\n",
            "[\u001b[36m11-08 07:26:20\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 24/63 | 0.20 it/sec | loss 2.8846\u001b[0m\n",
            "[\u001b[36m11-08 07:27:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 36/63 | 0.22 it/sec | loss 2.8107\u001b[0m\n",
            "[\u001b[36m11-08 07:27:56\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 48/63 | 0.22 it/sec | loss 2.7839\u001b[0m\n",
            "[\u001b[36m11-08 07:28:46\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 9 | 60/63 | 0.23 it/sec | loss 2.7569\u001b[0m\n",
            "[\u001b[36m11-08 07:28:49\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 9 | loss=2.7321 | duration=273.8091\u001b[0m\n",
            "[\u001b[36m11-08 07:29:18\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 3/15 | 0.14 it/sec | loss 6.7529\u001b[0m\n",
            "[\u001b[36m11-08 07:29:36\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 6/15 | 0.15 it/sec | loss 6.8063\u001b[0m\n",
            "[\u001b[36m11-08 07:29:37\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 9/15 | 0.21 it/sec | loss 6.7749\u001b[0m\n",
            "[\u001b[36m11-08 07:29:58\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 9 | 12/15 | 0.19 it/sec | loss 6.7930\u001b[0m\n",
            "[\u001b[36m11-08 07:29:58\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 9 | loss=6.7668 | duration=69.0633\u001b[0m\n",
            "[\u001b[36m11-08 07:29:58\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 07:31:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 12/63 | 0.19 it/sec | loss 2.2512\u001b[0m\n",
            "[\u001b[36m11-08 07:31:58\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 24/63 | 0.21 it/sec | loss 2.1845\u001b[0m\n",
            "[\u001b[36m11-08 07:32:59\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 36/63 | 0.21 it/sec | loss 2.1651\u001b[0m\n",
            "[\u001b[36m11-08 07:33:44\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 48/63 | 0.22 it/sec | loss 2.1610\u001b[0m\n",
            "[\u001b[36m11-08 07:34:29\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 10 | 60/63 | 0.23 it/sec | loss 2.1417\u001b[0m\n",
            "[\u001b[36m11-08 07:34:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 10 | loss=2.1185 | duration=284.6620\u001b[0m\n",
            "[\u001b[36m11-08 07:35:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 3/15 | 0.15 it/sec | loss 7.4635\u001b[0m\n",
            "[\u001b[36m11-08 07:35:23\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 6/15 | 0.18 it/sec | loss 7.5351\u001b[0m\n",
            "[\u001b[36m11-08 07:35:36\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 9/15 | 0.19 it/sec | loss 7.4927\u001b[0m\n",
            "[\u001b[36m11-08 07:35:48\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 10 | 12/15 | 0.20 it/sec | loss 7.4765\u001b[0m\n",
            "[\u001b[36m11-08 07:35:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 10 | loss=7.4210 | duration=69.0486\u001b[0m\n",
            "[\u001b[36m11-08 07:35:52\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 07:37:06\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 12/63 | 0.18 it/sec | loss 1.6364\u001b[0m\n",
            "[\u001b[36m11-08 07:37:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 24/63 | 0.21 it/sec | loss 1.6963\u001b[0m\n",
            "[\u001b[36m11-08 07:38:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 36/63 | 0.21 it/sec | loss 1.6659\u001b[0m\n",
            "[\u001b[36m11-08 07:39:34\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 48/63 | 0.22 it/sec | loss 1.6132\u001b[0m\n",
            "[\u001b[36m11-08 07:40:32\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 11 | 60/63 | 0.22 it/sec | loss 1.6148\u001b[0m\n",
            "[\u001b[36m11-08 07:40:33\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 11 | loss=1.5977 | duration=279.8534\u001b[0m\n",
            "[\u001b[36m11-08 07:41:01\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 3/15 | 0.14 it/sec | loss 7.7692\u001b[0m\n",
            "[\u001b[36m11-08 07:41:20\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 6/15 | 0.15 it/sec | loss 7.7660\u001b[0m\n",
            "[\u001b[36m11-08 07:41:25\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 9/15 | 0.19 it/sec | loss 7.7390\u001b[0m\n",
            "[\u001b[36m11-08 07:41:41\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 11 | 12/15 | 0.19 it/sec | loss 7.7217\u001b[0m\n",
            "[\u001b[36m11-08 07:41:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 11 | loss=7.7140 | duration=69.8513\u001b[0m\n",
            "[\u001b[36m11-08 07:41:43\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "[\u001b[36m11-08 07:42:58\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 12/63 | 0.17 it/sec | loss 1.1649\u001b[0m\n",
            "[\u001b[36m11-08 07:43:46\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 24/63 | 0.20 it/sec | loss 1.1718\u001b[0m\n",
            "[\u001b[36m11-08 07:44:52\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 36/63 | 0.20 it/sec | loss 1.1782\u001b[0m\n",
            "[\u001b[36m11-08 07:45:35\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 48/63 | 0.21 it/sec | loss 1.1590\u001b[0m\n",
            "[\u001b[36m11-08 07:46:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 12 | 60/63 | 0.22 it/sec | loss 1.1405\u001b[0m\n",
            "[\u001b[36m11-08 07:46:29\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 12 | loss=1.1327 | duration=285.9575\u001b[0m\n",
            "[\u001b[36m11-08 07:47:00\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 3/15 | 0.13 it/sec | loss 8.3247\u001b[0m\n",
            "[\u001b[36m11-08 07:47:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 6/15 | 0.17 it/sec | loss 8.1962\u001b[0m\n",
            "[\u001b[36m11-08 07:47:26\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 9/15 | 0.18 it/sec | loss 8.1351\u001b[0m\n",
            "[\u001b[36m11-08 07:47:42\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 12 | 12/15 | 0.18 it/sec | loss 8.1193\u001b[0m\n",
            "[\u001b[36m11-08 07:47:43\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 12 | loss=8.0614 | duration=74.0815\u001b[0m\n",
            "[\u001b[36m11-08 07:47:43\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[33mWARNING\u001b[0m] - Model valid_loss did not improve for 10 epochs. Stopping the training.\u001b[0m\n",
            "[\u001b[36m11-08 07:47:43\u001b[0m][\u001b[34mbm.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Scale Reject | Ratio 0.000%\u001b[0m\n",
            "\u001b[1mExecutor:\u001b[0m All workers completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copyfile('/content/brainmagick/outputs/xps/f2870bd1/tensorboard/events.out.tfevents.1701177019.6ba44a4dd73e.30269.0', '/content/brainmagick/outputs/grids/mygrid/f2870bd1/tensorboard/events.out.tfevents.1701177019.6ba44a4dd73e.30269.0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ny7e_J3dVU1A",
        "outputId": "a6fbfaac-6709-4a0f-d359-c5e76f693c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/brainmagick/outputs/grids/mygrid/f2870bd1/tensorboard/events.out.tfevents.1701177019.6ba44a4dd73e.30269.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP4LMfCiMBcvIMua9fat6Li",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}